# thesis 
by Marina Vrentzou for Leiden University

Supervisors: Prof. Dr. Stephan Raaijmakers  and Dr. J. Prokic, Assistant Professor

With kind thanks to Steven Vethman

Year: 2022

### Abstract
Gender bias is an identified issue in recruitment which is often transmitted through linguistic means in job postings. Language models utilised in the hiring process appear to also reflect this type of bias resulting in unfair evaluations and therefore reinforcing gender inequality and discrimination, particularly against marginalised groups. Experimental research has demonstrated the effects gendered wording has on potential candidates, while extensive work in the field of Natural Language Processing (NLP) has investigated the predominance of gender bias in language models. By integrating ideas from the fields of Sociolinguistics and NLP, this thesis explores the level of agreement between human perceptions of gender bias in job postings and revealed gender bias in NLP models, specifically, BERT. Furthermore, it assesses whether context words trigger individuals' perceptions, similar to BERT. Following a mixed-methods approach, both humans and BERT are submitted to an experimental gender bias detection task, addressing shared job postings data. The results show a significant difference between BERT and men in the attribution of genders, while little overlap was reported in the indicative words of the female gender between BERT and women. The reasons behind people's decisions were investigated through a thematic analysis. 


### Note
This thesis and its accompanying datasets are for academic purposes only. For more information, please contact @MarinaVrentzou
